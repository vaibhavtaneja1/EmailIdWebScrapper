{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"workflow.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "import re\n",
    "import numpy as np\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get colleges/universities list\n",
    "data = pd.read_csv(\"\\\\data\\\\AllPrivateUniversities.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "collegesList = list(data['College Name'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "USER_AGENT = {'User-Agent':'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/61.0.3163.100 Safari/537.36'}\n",
    "\n",
    "# fetch google results\n",
    "def fetch_results(search_term, number_results, language_code):\n",
    "    assert isinstance(search_term, str), 'Search term must be a string'\n",
    "    assert isinstance(number_results, int), 'Number of results must be an integer'\n",
    "    escaped_search_term = search_term.replace(' ', '+')\n",
    " \n",
    "    google_url = 'https://www.google.com/search?q={}&num={}&hl={}'.format(escaped_search_term, number_results, language_code)\n",
    "    response = requests.get(google_url, headers=USER_AGENT)\n",
    "    response.raise_for_status()\n",
    " \n",
    "    return search_term, response.text\n",
    "\n",
    "# fetch first url from google results\n",
    "def parse_results(html, keyword):\n",
    "    soup = BeautifulSoup(html, 'html.parser')\n",
    " \n",
    "    found_results = []\n",
    "    result_block = soup.find_all('div', attrs={'class': 'g'})\n",
    "    for result in result_block:\n",
    "        link = result.find('a', href=True)\n",
    "        found_results.append(link.attrs['href'])\n",
    "    return found_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initializing the blank list\n",
    "urls = []\n",
    "for college in collegesList:\n",
    "    if ('POLYTECHNIC' in college):\n",
    "        continue\n",
    "    else:\n",
    "        # call fetch function to get results from google\n",
    "        keyword, html = fetch_results(college+'computer science faculty', 1, 'en')\n",
    "        # pull first url from google results\n",
    "        url_single = parse_results(html,keyword)\n",
    "        # append in urls list\n",
    "        urls.append(url_single[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# regular expression format builder.\n",
    "# here we are trying all possible combinations in which we can find the email ids such as abc@xyz.com OR abc[AT]xyz[DOT]com etc.\n",
    "\n",
    "before_at = r'([\\w\\.-])+'\n",
    "at_str = r'(@|(\\[(AT|at)\\]))'\n",
    "after_at = r'[A-Za-z0-9]+'\n",
    "dot = r'(\\.|(\\[(DOT|dot)\\]))'\n",
    "after_dot = r'[a-zA-Z]+'\n",
    "reg_exp_pattern = before_at + at_str + after_at + dot + after_dot + r'(' + dot + after_dot + r')?'\n",
    "url_emails = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "for url in urls:\n",
    "    try:\n",
    "        # get the response from given url\n",
    "        response = requests.get(url, timeout = 120) # timeout is for 1 min\n",
    "    except:\n",
    "        continue\n",
    "    # status code 200 is success\n",
    "    if response.status_code == 200:\n",
    "        reg = re.compile(reg_exp_pattern)\n",
    "        ids = reg.finditer(response.text)\n",
    "        \n",
    "        emailids = [match.group() for match in ids]\n",
    "        emailids = list(set(emailids))\n",
    "        \n",
    "        if len(emailids) > 0:\n",
    "            # remove email ids from free domains\n",
    "            gmail_exp = re.compile(r'.*(gmail|yahoo|hotmail|rediff|aol\\.).*')\n",
    "            removals = []\n",
    "            for email in emailids:\n",
    "                junk_matches = gmail_exp.finditer(email)\n",
    "                removals.extend([junk_match.group() for junk_match in junk_matches])\n",
    "            \n",
    "            emailids = [email for email in emailids if email not in removals]\n",
    "                \n",
    "            url_emails[url] = emailids\n",
    "    else:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({'URL':[], 'EmailId':[]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "for url in url_emails.keys():\n",
    "    if len(url_emails[url]) > 0:\n",
    "        urlList = [url]\n",
    "        valueList = url_emails[url]\n",
    "        urlList *= len(valueList)\n",
    "        dataSet = pd.DataFrame({'URL':urlList, 'EmailId':valueList})\n",
    "        df = pd.concat((df,dataSet), axis = 0, ignore_index = True )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "pattern = re.compile(r'.*(principal|info|support|admission|enquiry|admin|feedback|contact|office|alumni|media|exams|technical|library|finance|tpo|membership|director|webmaster|registrar).*@.*')\n",
    "vals = []\n",
    "# pull junk ids from the dataset and push it in\n",
    "for c in df.EmailId:\n",
    "    col  = pattern.finditer(c)\n",
    "    vals.extend([m.group() for m in col])\n",
    "\n",
    "for val in vals:\n",
    "    index_num = df[df['EmailId'] == val].index\n",
    "    df.drop(index_num, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('\\\\output\\\\output.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "72219db253b3eb7f583b36325dc6dd1113beb44a2e268325932a30f711b11a18"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
